<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Elih - AI Assistant</title>
    <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <style>
        /* General Styles */
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            height: 100vh;
            background: #f5f5f5;
        }

        /* Chat Container */
        #chat-container {
            flex: 1;
            display: flex;
            flex-direction: column;
            padding: 20px;
            overflow-y: auto;
            background: #ffffff;
        }

        /* Message Bubbles */
        .message {
            max-width: 70%;
            margin: 10px;
            padding: 12px 16px;
            border-radius: 12px;
            position: relative;
        }

        .user {
            background: #007bff;
            color: white;
            align-self: flex-end;
        }

        .assistant {
            background: #e9ecef;
            color: #333;
            align-self: flex-start;
        }

        /* Voice Message Styles */
        .voice-message {
            display: flex;
            align-items: center;
            padding: 8px 12px;
            border-radius: 20px;
            background: #f1f3f4;
        }

        .play-button {
            width: 24px;
            height: 24px;
            margin-right: 8px;
            cursor: pointer;
        }

        /* Input Container */
        #input-container {
            display: flex;
            align-items: center;
            padding: 10px;
            background: #ffffff;
            border-top: 1px solid #ddd;
            gap: 10px;
        }

        #voiceButton {
            padding: 10px;
            border-radius: 50%;
            border: none;
            background: #007bff;
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        #voiceButton.recording {
            background: #dc3545;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        /* Loading Animation */
        .loading-dots span {
            animation: bounce 1.4s infinite ease-in-out;
        }

        @keyframes bounce {
            0%, 80%, 100% { transform: translateY(0); }
            40% { transform: translateY(-8px); }
        }
    </style>
</head>
<body>
    <div id="chat-container"></div>
    <div id="input-container">
        <button id="voiceButton">ðŸŽ¤</button>
        <input type="text" id="userInput" placeholder="Type or record message...">
        <button id="sendBtn">Send</button>
    </div>

    <!-- Azure and Supabase SDKs -->
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2"></script>
    <script>
        // Azure Configuration
        const AZURE_KEY = 'CSPdFdwXsQ2cnL9dtd0qNONQHv6IMGoT6nqlDwAKyjlLmFApkrbAJQQJ99ALACYeBjFXJ3w3AAAYACOGq0mA';
        const AZURE_REGION = 'eastus';
        const SYNTHESIS_VOICE = 'en-US-SaraNeural';
        
        // Speech SDK Objects
        let recognizer;
        let mediaRecorder;
        let audioChunks = [];
        let synthesisPlayer;

        // Initialize Speech SDK
        (async function() {
            const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(AZURE_KEY, AZURE_REGION);
            speechConfig.speechRecognitionLanguage = "en-US";
            
            // Setup synthesizer
            const audioConfig = SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
            synthesisPlayer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);
        })();

        // Voice Recording Logic
        document.getElementById('voiceButton').addEventListener('mousedown', startRecording);
        document.getElementById('voiceButton').addEventListener('mouseup', stopRecording);

        async function startRecording() {
            audioChunks = [];
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            mediaRecorder.start();
            this.classList.add('recording');
        }

        async function stopRecording() {
            mediaRecorder.stop();
            this.classList.remove('recording');
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks);
                const audioUrl = URL.createObjectURL(audioBlob);
                await processAudio(audioUrl);
            };
        }

        // Speech to Text Processing
        async function processAudio(audioUrl) {
            const audioConfig = SpeechSDK.AudioConfig.fromWavFileInput(fetch(audioUrl));
            recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);
            
            recognizer.recognizeOnceAsync(result => {
                if (result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
                    document.getElementById('userInput').value = result.text;
                    sendMessage();
                }
            });
        }

        // Text to Speech Processing
        async function synthesizeSpeech(text) {
            return new Promise((resolve) => {
                synthesisPlayer.speakTextAsync(text, result => {
                    if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                        const audioUrl = URL.createObjectURL(new Blob([result.audioData]));
                        resolve(audioUrl);
                    }
                });
            });
        }

        // Modified Message Handling
        async function sendMessage() {
            const input = document.getElementById('userInput');
            const userInput = input.value.trim();
            if (!userInput) return;

            // Add user message
            addMessage(userInput, 'user');
            input.value = '';

            // Show dynamic loading
            const loadingTime = Math.min(Math.max(userInput.length * 20, 1000), 5000);
            showLoading(loadingTime);

            try {
                // Get AI response
                const aiResponse = await getAIResponse(userInput,"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");
                
                // Convert to speech
                const audioUrl = await synthesizeSpeech(aiResponse);
                
                // Add response with audio
                addMessage(aiResponse, 'assistant', audioUrl);

            } catch (error) {
                console.error("Error:", error);
            }
        }

        // Add message with optional audio
        function addMessage(content, role, audioUrl = null) {
            const container = document.getElementById('chat-container');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;

            if (audioUrl) {
                messageDiv.innerHTML = `
                    <div class="voice-message">
                        <svg class="play-button" viewBox="0 0 24 24" onclick="playAudio('${audioUrl}')">
                            <path fill="currentColor" d="M8 5v14l11-7z"/>
                        </svg>
                        ${content}
                    </div>
                `;
            } else {
                messageDiv.textContent = content;
            }

            container.appendChild(messageDiv);
            container.scrollTop = container.scrollHeight;
        }

        // Audio Playback
        function playAudio(url) {
            new Audio(url).play();
        }

        // Dynamic Loading Animation
        function showLoading(duration) {
            const dots = document.createElement('div');
            dots.className = 'loading-dots';
            dots.innerHTML = '<span></span><span></span><span></span>';
            
            const tempMessage = document.createElement('div');
            tempMessage.className = 'message assistant';
            tempMessage.appendChild(dots);
            
            document.getElementById('chat-container').appendChild(tempMessage);
            setTimeout(() => tempMessage.remove(), duration);
        }

        // Your existing AI integration functions
        async function getAIResponse(prompt) {
            // Your existing OpenRouter/AI logic here
            return "This is a sample response from the AI.";
        }
    </script>
</body>
</html>
